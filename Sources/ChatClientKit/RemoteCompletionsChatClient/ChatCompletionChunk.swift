//
//  Created by ktiays on 2025/2/12.
//  Copyright (c) 2025 ktiays. All rights reserved.
//

import Foundation

/// Represents a streamed chunk of a chat completion response returned by a provider.
///
/// https://platform.openai.com/docs/api-reference/chat/streaming
public struct ChatCompletionChunk: Sendable, Decodable {
    /// A list of chat completion choices. Can contain more than one element if
    /// ChatCompletionRequestBody's `n` property is greater than 1.
    public var choices: [Choice]
}

public extension ChatCompletionChunk {
    /// https://platform.openai.com/docs/api-reference/chat/streaming#chat/streaming-choices
    struct Choice: Sendable, Decodable {
        /// A chat completion delta generated by streamed model responses.
        public let delta: Delta

        /// The reason the model stopped generating tokens.
        ///
        /// This will be stop if the model hit a natural stop point or a provided stop sequence, length
        /// if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag
        /// from our content filters, or `tool_calls` if the model called a tool.
        public let finishReason: String?

        /// The index of the choice in the list of choices.
        public let index: Int?

        enum CodingKeys: String, CodingKey {
            case delta
            case finishReason = "finish_reason"
            case index
        }

        public init(delta: Delta, finishReason: String? = nil, index: Int? = nil) {
            self.delta = delta
            self.finishReason = finishReason
            self.index = index
        }
    }
}

public extension ChatCompletionChunk.Choice {
    /// A chat completion delta generated by streamed model responses.
    struct Delta: Sendable, Decodable {
        public let content: String?
        public let reasoning: String?
        public let reasoningContent: String?
        public let role: String?
        public let toolCalls: [ToolCall]?
        public let images: [CompletionImageCollector]?

        enum CodingKeys: String, CodingKey {
            case content
            case reasoning
            case reasoningContent = "reasoning_content"
            case role
            case toolCalls = "tool_calls"
            case images = "image"
        }

        public init(
            content: String? = nil,
            reasoning: String? = nil,
            reasoningContent: String? = nil,
            role: String? = nil,
            toolCalls: [ToolCall]? = nil,
            images: [CompletionImageCollector]? = nil,
        ) {
            self.content = content
            self.reasoning = reasoning
            self.reasoningContent = reasoningContent
            self.role = role
            self.toolCalls = toolCalls
            self.images = images
        }
    }
}

public extension ChatCompletionChunk.Choice.Delta {
    struct ToolCall: Sendable, Decodable {
        public let index: Int?

        /// The ID of the tool call.
        public let id: String?

        /// The type of the tool. Currently, only "function" is supported.
        public let type: String?

        /// The function to call
        public let function: Function?
    }
}

public extension ChatCompletionChunk.Choice.Delta.ToolCall {
    struct Function: Sendable, Decodable {
        /// The name of the function to call.
        public let name: String?

        /// The arguments to call the function with, as generated by the model in JSON format.
        /// Note that the model does not always generate valid JSON, and may hallucinate parameters not
        /// defined by your function schema. Validate the arguments in your code before calling your function.
        public let arguments: String?
    }
}
